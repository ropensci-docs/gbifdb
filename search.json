[{"path":"https://docs.ropensci.org/gbifdb/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to gbifdb","title":"Contributing to gbifdb","text":"outlines propose change gbifdb. detailed info contributing , tidyverse packages, please see development contributing guide.","code":""},{"path":"https://docs.ropensci.org/gbifdb/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to gbifdb","text":"can fix typos, spelling mistakes, grammatical errors documentation directly using GitHub web interface, long changes made source file. generally means ’ll need edit roxygen2 comments .R, .Rd file. can find .R file generates .Rd reading comment first line.","code":""},{"path":"https://docs.ropensci.org/gbifdb/CONTRIBUTING.html","id":"bigger-changes","dir":"","previous_headings":"","what":"Bigger changes","title":"Contributing to gbifdb","text":"want make bigger change, ’s good idea first file issue make sure someone team agrees ’s needed. ’ve found bug, please file issue illustrates bug minimal reprex (also help write unit test, needed).","code":""},{"path":"https://docs.ropensci.org/gbifdb/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"Bigger changes","what":"Pull request process","title":"Contributing to gbifdb","text":"Fork package clone onto computer. haven’t done , recommend using usethis::create_from_github(\"cboettig/gbifdb\", fork = TRUE). Install development dependencies devtools::install_dev_deps(), make sure package passes R CMD check running devtools::check(). R CMD check doesn’t pass cleanly, ’s good idea ask help continuing. Create Git branch pull request (PR). recommend using usethis::pr_init(\"brief-description--change\"). Make changes, commit git, create PR running usethis::pr_push(), following prompts browser. title PR briefly describe change. body PR contain Fixes #issue-number. user-facing changes, add bullet top NEWS.md (.e. just first header). Follow style described https://style.tidyverse.org/news.html.","code":""},{"path":"https://docs.ropensci.org/gbifdb/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Bigger changes","what":"Code style","title":"Contributing to gbifdb","text":"New code follow tidyverse style guide. can use styler package apply styles, please don’t restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"https://docs.ropensci.org/gbifdb/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to gbifdb","text":"Please note gbifdb project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":"https://docs.ropensci.org/gbifdb/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"Apache License","title":"Apache License","text":"Version 2.0, January 2004 <http://www.apache.org/licenses/>","code":""},{"path":[]},{"path":"https://docs.ropensci.org/gbifdb/LICENSE.html","id":"1-definitions","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"1. Definitions","title":"Apache License","text":"“License” shall mean terms conditions use, reproduction, distribution defined Sections 1 9 document. “Licensor” shall mean copyright owner entity authorized copyright owner granting License. “Legal Entity” shall mean union acting entity entities control, controlled , common control entity. purposes definition, “control” means () power, direct indirect, cause direction management entity, whether contract otherwise, (ii) ownership fifty percent (50%) outstanding shares, (iii) beneficial ownership entity. “” (“”) shall mean individual Legal Entity exercising permissions granted License. “Source” form shall mean preferred form making modifications, including limited software source code, documentation source, configuration files. “Object” form shall mean form resulting mechanical transformation translation Source form, including limited compiled object code, generated documentation, conversions media types. “Work” shall mean work authorship, whether Source Object form, made available License, indicated copyright notice included attached work (example provided Appendix ). “Derivative Works” shall mean work, whether Source Object form, based (derived ) Work editorial revisions, annotations, elaborations, modifications represent, whole, original work authorship. purposes License, Derivative Works shall include works remain separable , merely link (bind name) interfaces , Work Derivative Works thereof. “Contribution” shall mean work authorship, including original version Work modifications additions Work Derivative Works thereof, intentionally submitted Licensor inclusion Work copyright owner individual Legal Entity authorized submit behalf copyright owner. purposes definition, “submitted” means form electronic, verbal, written communication sent Licensor representatives, including limited communication electronic mailing lists, source code control systems, issue tracking systems managed , behalf , Licensor purpose discussing improving Work, excluding communication conspicuously marked otherwise designated writing copyright owner “Contribution.” “Contributor” shall mean Licensor individual Legal Entity behalf Contribution received Licensor subsequently incorporated within Work.","code":""},{"path":"https://docs.ropensci.org/gbifdb/LICENSE.html","id":"2-grant-of-copyright-license","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"2. Grant of Copyright License","title":"Apache License","text":"Subject terms conditions License, Contributor hereby grants perpetual, worldwide, non-exclusive, -charge, royalty-free, irrevocable copyright license reproduce, prepare Derivative Works , publicly display, publicly perform, sublicense, distribute Work Derivative Works Source Object form.","code":""},{"path":"https://docs.ropensci.org/gbifdb/LICENSE.html","id":"3-grant-of-patent-license","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"3. Grant of Patent License","title":"Apache License","text":"Subject terms conditions License, Contributor hereby grants perpetual, worldwide, non-exclusive, -charge, royalty-free, irrevocable (except stated section) patent license make, made, use, offer sell, sell, import, otherwise transfer Work, license applies patent claims licensable Contributor necessarily infringed Contribution(s) alone combination Contribution(s) Work Contribution(s) submitted. institute patent litigation entity (including cross-claim counterclaim lawsuit) alleging Work Contribution incorporated within Work constitutes direct contributory patent infringement, patent licenses granted License Work shall terminate date litigation filed.","code":""},{"path":"https://docs.ropensci.org/gbifdb/LICENSE.html","id":"4-redistribution","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"4. Redistribution","title":"Apache License","text":"may reproduce distribute copies Work Derivative Works thereof medium, without modifications, Source Object form, provided meet following conditions: () must give recipients Work Derivative Works copy License; (b) must cause modified files carry prominent notices stating changed files; (c) must retain, Source form Derivative Works distribute, copyright, patent, trademark, attribution notices Source form Work, excluding notices pertain part Derivative Works; (d) Work includes “NOTICE” text file part distribution, Derivative Works distribute must include readable copy attribution notices contained within NOTICE file, excluding notices pertain part Derivative Works, least one following places: within NOTICE text file distributed part Derivative Works; within Source form documentation, provided along Derivative Works; , within display generated Derivative Works, wherever third-party notices normally appear. contents NOTICE file informational purposes modify License. may add attribution notices within Derivative Works distribute, alongside addendum NOTICE text Work, provided additional attribution notices construed modifying License. may add copyright statement modifications may provide additional different license terms conditions use, reproduction, distribution modifications, Derivative Works whole, provided use, reproduction, distribution Work otherwise complies conditions stated License.","code":""},{"path":"https://docs.ropensci.org/gbifdb/LICENSE.html","id":"5-submission-of-contributions","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"5. Submission of Contributions","title":"Apache License","text":"Unless explicitly state otherwise, Contribution intentionally submitted inclusion Work Licensor shall terms conditions License, without additional terms conditions. Notwithstanding , nothing herein shall supersede modify terms separate license agreement may executed Licensor regarding Contributions.","code":""},{"path":"https://docs.ropensci.org/gbifdb/LICENSE.html","id":"6-trademarks","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"6. Trademarks","title":"Apache License","text":"License grant permission use trade names, trademarks, service marks, product names Licensor, except required reasonable customary use describing origin Work reproducing content NOTICE file.","code":""},{"path":"https://docs.ropensci.org/gbifdb/LICENSE.html","id":"7-disclaimer-of-warranty","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"7. Disclaimer of Warranty","title":"Apache License","text":"Unless required applicable law agreed writing, Licensor provides Work (Contributor provides Contributions) “” BASIS, WITHOUT WARRANTIES CONDITIONS KIND, either express implied, including, without limitation, warranties conditions TITLE, NON-INFRINGEMENT, MERCHANTABILITY, FITNESS PARTICULAR PURPOSE. solely responsible determining appropriateness using redistributing Work assume risks associated exercise permissions License.","code":""},{"path":"https://docs.ropensci.org/gbifdb/LICENSE.html","id":"8-limitation-of-liability","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"8. Limitation of Liability","title":"Apache License","text":"event legal theory, whether tort (including negligence), contract, otherwise, unless required applicable law (deliberate grossly negligent acts) agreed writing, shall Contributor liable damages, including direct, indirect, special, incidental, consequential damages character arising result License use inability use Work (including limited damages loss goodwill, work stoppage, computer failure malfunction, commercial damages losses), even Contributor advised possibility damages.","code":""},{"path":"https://docs.ropensci.org/gbifdb/LICENSE.html","id":"9-accepting-warranty-or-additional-liability","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"9. Accepting Warranty or Additional Liability","title":"Apache License","text":"redistributing Work Derivative Works thereof, may choose offer, charge fee , acceptance support, warranty, indemnity, liability obligations /rights consistent License. However, accepting obligations, may act behalf sole responsibility, behalf Contributor, agree indemnify, defend, hold Contributor harmless liability incurred , claims asserted , Contributor reason accepting warranty additional liability. END TERMS CONDITIONS","code":""},{"path":"https://docs.ropensci.org/gbifdb/LICENSE.html","id":"appendix-how-to-apply-the-apache-license-to-your-work","dir":"","previous_headings":"","what":"APPENDIX: How to apply the Apache License to your work","title":"Apache License","text":"apply Apache License work, attach following boilerplate notice, fields enclosed brackets [] replaced identifying information. (Don’t include brackets!) text enclosed appropriate comment syntax file format. also recommend file class name description purpose included “printed page” copyright notice easier identification within third-party archives.","code":"Copyright [yyyy] [name of copyright owner]  Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at    http://www.apache.org/licenses/LICENSE-2.0  Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."},{"path":"https://docs.ropensci.org/gbifdb/articles/intro.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Intro to gbifdb","text":"NOTE: gbifdb currently requires dev version duckdb, can install using: development version GitHub : gbifdb dependencies: duckdb DBI required.","code":"install.packages(\"https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz\", repos = NULL) # install.packages(\"devtools\") devtools::install_github(\"cboettig/gbifdb\")"},{"path":"https://docs.ropensci.org/gbifdb/articles/intro.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting Started","title":"Intro to gbifdb","text":"","code":"library(gbifdb) library(dplyr)  # optional, for dplyr-based operations"},{"path":"https://docs.ropensci.org/gbifdb/articles/intro.html","id":"remote-data-access","dir":"Articles","previous_headings":"Getting Started","what":"Remote data access","title":"Intro to gbifdb","text":"begin working GBIF data directly without downloading data first, simply establish remote connection using gbif_remote(). can now perform dplyr operations: default, relies arrow connection, currently lacks support complex windowed operations dplyr. user can specify option to_duckdb = TRUE gbif_remote() (simply pass connection arrow::to_duckdb()) create duckdb connection. slightly slower time. Keep mind database connection, use non-dplyr functions user generally need call dplyr::collect(), pulls data working memory. sure subset data appropriately first (e.g. filter, summarise, etc), attempting collect() large table probably exceed available RAM crash R session! using gbif_remote() connection, /O operations conducted network storage instead local disk, without downloading full dataset first. operations considerably slower download entire dataset first (see , unless AWS cloud instance region remote host), avoid download step -together, may necessary 100+ GB free storage space time download whole dataset first (e.g. one-queries).","code":"gbif <- gbif_remote() gbif %>%   filter(phylum == \"Chordata\", year > 1990) %>%   count(class, year) #> FileSystemDataset (query) #> class: string #> year: int32 #> n: int32 #>  #> * Grouped by class #> See $.data for the source Arrow object"},{"path":"https://docs.ropensci.org/gbifdb/articles/intro.html","id":"local-data","dir":"Articles","previous_headings":"Getting Started","what":"Local data","title":"Intro to gbifdb","text":"extended analysis GBIF, users may prefer download entire GBIF parquet data first. requires 100 GB free disk space, time-consuming process first time. However, downloaded, future queries run much much faster, particularly network-limited. Users can download current release GBIF local storage like : default, download dir given gbif_dir(). alternative directory can set argument, setting path environmental variable, GBIF_HOME. downloaded parquet-formatted GBIF data, simply point gbif_conn() directory containing parquet files initialize connection. (default, gbif_conn() look data configurable directory given gbif_dir()). resulting connection can used dplyr::tbl() access full gbif data: Now, can use dplyr perform standard queries: Recall database connections dplyr, data remains database (.e. disk, working RAM). fine operations using dplyr/tidyr functions can translated SQL. Using functions can usually reduce resulting table something much smaller, can pulled memory R analysis using collect():","code":"gbif_download() conn <- gbif_conn() gbif <- tbl(conn, \"gbif\") gbif #> # Source:   table<gbif> [?? x 50] #> # Database: duckdb_connection #>        gbifid datasetkey  occurrenceid   kingdom phylum class order family genus #>         <dbl> <chr>       <chr>          <chr>   <chr>  <chr> <chr> <chr>  <chr> #>  1 1851456555 b234abf6-4… 03871B11FFA43… Animal… Echin… Holo… Dend… Cucum… Acti… #>  2 1851456618 b234abf6-4… 03871B11FFAA3… Animal… Echin… Holo… Dend… Scler… Clad… #>  3 1851456554 b234abf6-4… 03871B11FFA53… Animal… Echin… Holo… Dend… Cucum… Acti… #>  4 1851456620 b234abf6-4… 03871B11FFA03… Animal… Echin… Holo… Dend… Phyll… Tria… #>  5 1851456556 b234abf6-4… 03871B11FFA83… Animal… Echin… Holo… Dend… Scler… Glob… #>  6 1851456619 b234abf6-4… 03871B11FFA33… Animal… Echin… Holo… Dend… Phyll… Mass… #>  7 1851456623 b234abf6-4… 03871B11FFA03… Animal… Echin… Holo… Dend… Phyll… Tria… #>  8 1851456714 b234abf6-4… 03871B11FFAC3… Animal… Echin… Holo… Dend… Phyll… Mass… #>  9 1851456553 b234abf6-4… 03871B11FFAA3… Animal… Echin… Holo… Dend… Scler… Clad… #> 10 1851456622 b234abf6-4… 03871B11FFA53… Animal… Echin… Holo… Dend… Cucum… Acti… #> # … with more rows, and 41 more variables: species <chr>, #> #   infraspecificepithet <chr>, taxonrank <chr>, scientificname <chr>, #> #   verbatimscientificname <chr>, verbatimscientificnameauthorship <chr>, #> #   countrycode <chr>, locality <chr>, stateprovince <chr>, #> #   occurrencestatus <chr>, individualcount <int>, publishingorgkey <chr>, #> #   decimallatitude <dbl>, decimallongitude <dbl>, #> #   coordinateuncertaintyinmeters <dbl>, coordinateprecision <dbl>, … colnames(gbif) #>  [1] \"gbifid\"                           \"datasetkey\"                       #>  [3] \"occurrenceid\"                     \"kingdom\"                          #>  [5] \"phylum\"                           \"class\"                            #>  [7] \"order\"                            \"family\"                           #>  [9] \"genus\"                            \"species\"                          #> [11] \"infraspecificepithet\"             \"taxonrank\"                        #> [13] \"scientificname\"                   \"verbatimscientificname\"           #> [15] \"verbatimscientificnameauthorship\" \"countrycode\"                      #> [17] \"locality\"                         \"stateprovince\"                    #> [19] \"occurrencestatus\"                 \"individualcount\"                  #> [21] \"publishingorgkey\"                 \"decimallatitude\"                  #> [23] \"decimallongitude\"                 \"coordinateuncertaintyinmeters\"    #> [25] \"coordinateprecision\"              \"elevation\"                        #> [27] \"elevationaccuracy\"                \"depth\"                            #> [29] \"depthaccuracy\"                    \"eventdate\"                        #> [31] \"day\"                              \"month\"                            #> [33] \"year\"                             \"taxonkey\"                         #> [35] \"specieskey\"                       \"basisofrecord\"                    #> [37] \"institutioncode\"                  \"collectioncode\"                   #> [39] \"catalognumber\"                    \"recordnumber\"                     #> [41] \"identifiedby\"                     \"dateidentified\"                   #> [43] \"license\"                          \"rightsholder\"                     #> [45] \"recordedby\"                       \"typestatus\"                       #> [47] \"establishmentmeans\"               \"lastinterpreted\"                  #> [49] \"mediatype\"                        \"issue\" growth <- gbif %>%    filter(phylum == \"Chordata\", year > 1990) %>%   count(class, year) %>% arrange(year) growth #> # Source:     lazy query [?? x 3] #> # Database:   duckdb_connection #> # Groups:     class #> # Ordered by: year #>    class               year       n #>    <chr>              <int>   <dbl> #>  1 Aves                1991 3183184 #>  2 Mammalia            1991  100931 #>  3 Actinopterygii      1991  363791 #>  4 Amphibia            1991   18443 #>  5 Reptilia            1991   29806 #>  6 Elasmobranchii      1991   17521 #>  7 Holocephali         1991    1048 #>  8 Cephalaspidomorphi  1991    1152 #>  9 Thaliacea           1991     669 #> 10 Sarcopterygii       1991      13 #> # … with more rows library(ggplot2) library(forcats)  # GBIF: the global bird information facility? growth %>%    collect() %>%   mutate(class = fct_lump_n(class, 6)) %>%   ggplot(aes(year, n, fill=class)) + geom_col() +   ggtitle(\"GBIF observations by class\")"},{"path":"https://docs.ropensci.org/gbifdb/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Carl Boettiger. Author, maintainer.","code":""},{"path":"https://docs.ropensci.org/gbifdb/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Boettiger C (2024). gbifdb: High Performance Interface 'GBIF'. R package version 1.0.0, https://github.com/ropensci/gbifdb, https://docs.ropensci.org/gbifdb/.","code":"@Manual{,   title = {gbifdb: High Performance Interface to 'GBIF'},   author = {Carl Boettiger},   year = {2024},   note = {R package version 1.0.0, https://github.com/ropensci/gbifdb},   url = {https://docs.ropensci.org/gbifdb/}, }"},{"path":"https://docs.ropensci.org/gbifdb/index.html","id":"gbifdb","dir":"","previous_headings":"","what":"High Performance Interface to GBIF","title":"High Performance Interface to GBIF","text":"goal gbifdb provide relational database interface parquet based serializations gbif’s AWS snapshots public data 1. Instead requiring custom functions filtering selecting data central GBIF server (rgbif), gbifdb users can take advantage full array dplyr tidyr functions can automatically translated SQL dbplyr. Users already familiar SQL can construct SQL queries directly DBI instead. gbifdb sends queries duckdb, high-performance, columnar-oriented database engine runs entirely inside client, (unlike server-client databases MySQL Postgres, additional setup needed outside installing gbifdb.) duckdb able execute SQL queries directly -disk Parquet data files, side-stepping limitations available RAM need import data. ’s highly optimized implementation can faster even -memory operations dplyr. duckdb supports full set SQL instructions, including windowed operations like group_by+summarise well table joins. gbifdb two mechanisms providing database connections: one Parquet snapshot GBIF must first downloaded locally, second GBIF parquet snapshot can accessed directly Amazon Public Data Registry S3 bucket without downloading copy. latter approach faster one-operations also suitable using cloud-based computing provider region.","code":""},{"path":"https://docs.ropensci.org/gbifdb/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"High Performance Interface to GBIF","text":"development version GitHub : gbifdb dependencies: arrow, duckdb DBI required.","code":"# install.packages(\"devtools\") devtools::install_github(\"ropensci/gbifdb\")"},{"path":"https://docs.ropensci.org/gbifdb/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"High Performance Interface to GBIF","text":"","code":"library(gbifdb) library(dplyr)  # optional, for dplyr-based operations"},{"path":"https://docs.ropensci.org/gbifdb/index.html","id":"remote-data-access","dir":"","previous_headings":"Getting Started","what":"Remote data access","title":"High Performance Interface to GBIF","text":"begin working GBIF data directly without downloading data first, simply establish remote connection using gbif_remote(). can now perform dplyr operations: default, relies arrow connection, currently lacks support complex windowed operations dplyr. user can specify option to_duckdb = TRUE gbif_remote() (simply pass connection arrow::to_duckdb()) create duckdb connection. slightly slower time. Keep mind database connection, use non-dplyr functions user generally need call dplyr::collect(), pulls data working memory. sure subset data appropriately first (e.g. filter, summarise, etc), attempting collect() large table probably exceed available RAM crash R session! using gbif_remote() connection, /O operations conducted network storage instead local disk, without downloading full dataset first. Consequently, mechanism perform best platforms faster network connections. operations considerably slower download entire dataset first (see , unless AWS cloud instance region remote host), avoid download step -together, may necessary 100+ GB free storage space time download whole dataset first (e.g. one-queries).","code":"gbif <- gbif_remote() gbif %>%   filter(phylum == \"Chordata\", year > 1990) %>%   count(class, year) %>%   collect() #> # A tibble: 461 × 3 #>    class           year       n #>    <chr>          <int>   <int> #>  1 Actinopterygii  2003  696289 #>  2 Actinopterygii  2009 1152201 #>  3 Elasmobranchii  2009   67477 #>  4 Actinopterygii  2010 1348109 #>  5 Elasmobranchii  2003   22638 #>  6 Ascidiacea      2013    9151 #>  7 Actinopterygii  2002  777535 #>  8 Actinopterygii  2008 1311066 #>  9 Elasmobranchii  2008   64769 #> 10 Elasmobranchii  2002   21948 #> # … with 451 more rows"},{"path":"https://docs.ropensci.org/gbifdb/index.html","id":"local-data","dir":"","previous_headings":"Getting Started","what":"Local data","title":"High Performance Interface to GBIF","text":"extended analysis GBIF, users may prefer download entire GBIF parquet data first. requires 100 GB free disk space, time-consuming process first time. However, downloaded, future queries run much much faster, particularly network-limited. Users can download current release GBIF local storage like : default, download dir given gbif_dir(). alternative directory can provided setting environmental variable, GBIF_HOME, providing path directory containing parquet files directly. downloaded parquet-formatted GBIF data, gbif_local() establish connection local parquet files. Now, can use dplyr perform standard queries: Recall database connections dplyr, data remains database (.e. disk, working RAM). fine operations using dplyr/tidyr functions can translated SQL. Using functions can usually reduce resulting table something much smaller, can pulled memory R analysis using collect():","code":"gbif_download() gbif <- gbif_local() gbif #> # Source:   lazy query [?? x 48] #> # Database: duckdb_connection #>        gbifid datasetkey    occurrenceid kingdom phylum class order family genus #>         <dbl> <chr>         <chr>        <chr>   <chr>  <chr> <chr> <chr>  <chr> #>  1 1572326202 0e2c20a3-3c3… 7B3E9B63FF9… Animal… Arthr… <NA>  Aran… Capon… Medi… #>  2 1572326211 0e2c20a3-3c3… 7B3E9B63FF8… Animal… Arthr… <NA>  Aran… Capon… Medi… #>  3 1572326213 0e2c20a3-3c3… 7B3E9B63FF9… Animal… Arthr… <NA>  Aran… Capon… Medi… #>  4 1572326222 0e2c20a3-3c3… 7B3E9B63FF8… Animal… Arthr… <NA>  Aran… Capon… Medi… #>  5 1572326224 0e2c20a3-3c3… 7B3E9B63FF8… Animal… Arthr… <NA>  Aran… Capon… Medi… #>  6 1572326210 0e2c20a3-3c3… 7B3E9B63FF9… Animal… Arthr… <NA>  Aran… Capon… Medi… #>  7 1572326209 0e2c20a3-3c3… 7B3E9B63FF8… Animal… Arthr… <NA>  Aran… Capon… Medi… #>  8 1572326215 0e2c20a3-3c3… 7B3E9B63FF8… Animal… Arthr… <NA>  Aran… Capon… Medi… #>  9 1572326228 0e2c20a3-3c3… 7B3E9B63FF8… Animal… Arthr… <NA>  Aran… Capon… Medi… #> 10 1572326205 0e2c20a3-3c3… 7B3E9B63FF8… Animal… Arthr… <NA>  Aran… Capon… Medi… #> # … with more rows, and 39 more variables: species <chr>, #> #   infraspecificepithet <chr>, taxonrank <chr>, scientificname <chr>, #> #   verbatimscientificname <chr>, verbatimscientificnameauthorship <chr>, #> #   countrycode <chr>, locality <chr>, stateprovince <chr>, #> #   occurrencestatus <chr>, individualcount <int>, publishingorgkey <chr>, #> #   decimallatitude <dbl>, decimallongitude <dbl>, #> #   coordinateuncertaintyinmeters <dbl>, coordinateprecision <dbl>, … colnames(gbif) #>  [1] \"gbifid\"                           \"datasetkey\"                       #>  [3] \"occurrenceid\"                     \"kingdom\"                          #>  [5] \"phylum\"                           \"class\"                            #>  [7] \"order\"                            \"family\"                           #>  [9] \"genus\"                            \"species\"                          #> [11] \"infraspecificepithet\"             \"taxonrank\"                        #> [13] \"scientificname\"                   \"verbatimscientificname\"           #> [15] \"verbatimscientificnameauthorship\" \"countrycode\"                      #> [17] \"locality\"                         \"stateprovince\"                    #> [19] \"occurrencestatus\"                 \"individualcount\"                  #> [21] \"publishingorgkey\"                 \"decimallatitude\"                  #> [23] \"decimallongitude\"                 \"coordinateuncertaintyinmeters\"    #> [25] \"coordinateprecision\"              \"elevation\"                        #> [27] \"elevationaccuracy\"                \"depth\"                            #> [29] \"depthaccuracy\"                    \"eventdate\"                        #> [31] \"day\"                              \"month\"                            #> [33] \"year\"                             \"taxonkey\"                         #> [35] \"specieskey\"                       \"basisofrecord\"                    #> [37] \"institutioncode\"                  \"collectioncode\"                   #> [39] \"catalognumber\"                    \"recordnumber\"                     #> [41] \"identifiedby\"                     \"dateidentified\"                   #> [43] \"license\"                          \"rightsholder\"                     #> [45] \"recordedby\"                       \"typestatus\"                       #> [47] \"establishmentmeans\"               \"lastinterpreted\" growth <- gbif %>%   filter(phylum == \"Chordata\", year > 1990) %>%   count(class, year) %>% arrange(year) growth #> # Source:     lazy query [?? x 3] #> # Database:   duckdb_connection #> # Groups:     class #> # Ordered by: year #>    class               year      n #>    <chr>              <int>  <dbl> #>  1 Cephalaspidomorphi  1991   1152 #>  2 Elasmobranchii      1991  17521 #>  3 Ascidiacea          1991   1602 #>  4 Thaliacea           1991    669 #>  5 Amphibia            1991  18443 #>  6 Sarcopterygii       1991     13 #>  7 Leptocardii         1991     36 #>  8 <NA>                1991    912 #>  9 Actinopterygii      1991 363791 #> 10 Holocephali         1991   1048 #> # … with more rows library(ggplot2) library(forcats) # GBIF: the global bird information facility? growth %>%  collect() %>%   mutate(class = fct_lump_n(class, 6)) %>%   ggplot(aes(year, n, fill=class)) + geom_col() +   ggtitle(\"GBIF observations of vertebrates by class\")"},{"path":"https://docs.ropensci.org/gbifdb/index.html","id":"visualizing-all-of-gbif","dir":"","previous_headings":"","what":"Visualizing all of GBIF","title":"High Performance Interface to GBIF","text":"Database operations rounding provide easy way “rasterize” data spatial visualizations. quickly generate color intensity reflects logarithmic occurrence count pixel:","code":"library(terra) library(viridisLite)  db <- gbif_local() df <- db |> mutate(latitude = round(decimallatitude,1),                    longitude = round(decimallongitude,1)) |>    count(longitude, latitude) |>    collect() |>    mutate(n = log(n))  r <- rast(df, crs=\"epsg:4326\") plot(r, col= viridis(1e3), legend=FALSE, maxcell=6e6, colNA=\"black\", axes=FALSE)"},{"path":"https://docs.ropensci.org/gbifdb/index.html","id":"performance-notes","dir":"","previous_headings":"","what":"Performance notes","title":"High Performance Interface to GBIF","text":"parquet columnar-oriented dataset, performance can improved including select() call end dplyr function chain return columns actually need. can particularly helpful remote connections using gbif_remote().","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_dir.html","id":null,"dir":"Reference","previous_headings":"","what":"Default storage location — gbif_dir","title":"Default storage location — gbif_dir","text":"Default location can set env var GBIF_HOME, otherwise use default provided tools::R_user_dir()","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_dir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Default storage location — gbif_dir","text":"","code":"gbif_dir()"},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_dir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Default storage location — gbif_dir","text":"path gbif home directory directory","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_dir.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Default storage location — gbif_dir","text":"","code":"gbif_dir() #> [1] \"/github/home/.local/share/R/gbif\""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_download.html","id":null,"dir":"Reference","previous_headings":"","what":"Download GBIF data using minioclient — gbif_download","title":"Download GBIF data using minioclient — gbif_download","text":"Sync local directory selected release AWS copy GBIF","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_download.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download GBIF data using minioclient — gbif_download","text":"","code":"gbif_download(   version = gbif_version(),   dir = gbif_dir(),   bucket = gbif_default_bucket(),   region = \"\" )"},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_download.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download GBIF data using minioclient — gbif_download","text":"version Release date (YYYY-MM-DD) synced. detect latest version default. dir path local directory parquet files stored. Fine leave default, see gbif_dir(). bucket Name regional S3 bucket desired. Default \"gbif-open-data-us-east-1\". Select bucket closer compute location improved performance, e.g. European researchers may prefer \"gbif-open-data-eu-central-1\" etc. region bucket region (usually ignored? Just set bucket appropriately)","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_download.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download GBIF data using minioclient — gbif_download","text":"logical indicating success failure.","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_download.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Download GBIF data using minioclient — gbif_download","text":"Sync parquet files GBIF public data catalog, https://registry.opendata.aws/gbif/. Note data can also found Microsoft Cloud, https://planetarycomputer.microsoft.com/dataset/gbif Also, users may prefer download data using alternative interface work cloud-host machine data already available. Note, data include CC0 CC-licensed data GBIF coordinates passed automated quality checks, see https://github.com/gbif/occurrence/blob/master/aws-public-data.md.","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_download.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download GBIF data using minioclient — gbif_download","text":"","code":"if (FALSE) { # interactive() gbif_download() }"},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_example_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Return a path to the directory containing GBIF example parquet data — gbif_example_data","title":"Return a path to the directory containing GBIF example parquet data — gbif_example_data","text":"Return path directory containing GBIF example parquet data","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_example_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return a path to the directory containing GBIF example parquet data — gbif_example_data","text":"","code":"gbif_example_data()"},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_example_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return a path to the directory containing GBIF example parquet data — gbif_example_data","text":"path example occurrence data installed package.","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_example_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Return a path to the directory containing GBIF example parquet data — gbif_example_data","text":"example data taken first 1000 rows 2011-11-01 release parquet data.","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_example_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return a path to the directory containing GBIF example parquet data — gbif_example_data","text":"","code":"gbif_example_data() #> [1] \"/usr/local/lib/R/site-library/gbifdb/extdata/occurrence.parquet\""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_local.html","id":null,"dir":"Reference","previous_headings":"","what":"Local connection to a downloaded GBIF Parquet database — gbif_local","title":"Local connection to a downloaded GBIF Parquet database — gbif_local","text":"Local connection downloaded GBIF Parquet database","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_local.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Local connection to a downloaded GBIF Parquet database — gbif_local","text":"","code":"gbif_local(   dir = gbif_parquet_dir(version = gbif_version(local = TRUE)),   tblname = \"gbif\",   backend = c(\"arrow\", \"duckdb\"),   safe = TRUE )"},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_local.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Local connection to a downloaded GBIF Parquet database — gbif_local","text":"dir location downloaded GBIF parquet files tblname name database table backend choose duckdb arrow. safe logical. exclude columns mediatype issue? (default TRUE). varchar datatype columns substantially slows downs queries.","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_local.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Local connection to a downloaded GBIF Parquet database — gbif_local","text":"remote tibble tbl_sql class object","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_local.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Local connection to a downloaded GBIF Parquet database — gbif_local","text":"summary GBIF data, along column meanings can found https://github.com/gbif/occurrence/blob/master/aws-public-data.md","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_local.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Local connection to a downloaded GBIF Parquet database — gbif_local","text":"","code":"if (FALSE) { # interactive()  gbif <- gbif_local(gbif_example_data()) }"},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_remote.html","id":null,"dir":"Reference","previous_headings":"","what":"gbif remote — gbif_remote","title":"gbif remote — gbif_remote","text":"Connect GBIF remote directly. Can much faster downloading one-use using package server region data. See Details.","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_remote.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"gbif remote — gbif_remote","text":"","code":"gbif_remote(   version = gbif_version(),   bucket = gbif_default_bucket(),   safe = TRUE,   unset_aws = getOption(\"gbif_unset_aws\", TRUE),   endpoint_override = Sys.getenv(\"AWS_S3_ENDPOINT\", \"s3.amazonaws.com\"),   backend = c(\"arrow\", \"duckdb\"),   ... )"},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_remote.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"gbif remote — gbif_remote","text":"version GBIF snapshot date bucket GBIF bucket name (including region). default can also set using option gbif_default_bucket, see options. safe logical, default TRUE.  exclude columns mediatype issue? varchar datatype columns substantially slows downs queries. unset_aws Unset AWS credentials?  GBIF provided public bucket, credentials needed, AWS_ACCESS_KEY_ID AWS environmental variables set can cause connection fail.  default, unset set environmental variables duration R session. behavior can also turned globally setting option gbif_unset_aws FALSE (e.g. use alternative network endpoint) endpoint_override optional parameter arrow::s3_bucket() backend duckdb arrow ... additional parameters passed arrow::s3_bucket()","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_remote.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"gbif remote — gbif_remote","text":"remote tibble tbl_sql class object.","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_remote.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"gbif remote — gbif_remote","text":"Query performance dramatically improved queries return subset columns. Consider using explicit select() commands return columns need. summary GBIF data, along column meanings can found https://github.com/gbif/occurrence/blob/master/aws-public-data.md","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_remote.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"gbif remote — gbif_remote","text":"","code":"if (FALSE) { # interactive()  gbif <- gbif_remote() gbif() }"},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_version.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the latest gbif version string — gbif_version","title":"Get the latest gbif version string — gbif_version","text":"Can also return latest locally downloaded version, list versions","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_version.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the latest gbif version string — gbif_version","text":"","code":"gbif_version(   local = FALSE,   dir = gbif_dir(),   bucket = gbif_default_bucket(),   all = FALSE,   ... )"},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_version.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the latest gbif version string — gbif_version","text":"local Search local versions? logical, default FALSE. dir local directory (gbif_dir()) bucket remote bucket (region) checked show versions? (logical, default FALSE) ... additional arguments arrow::s3_bucket","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_version.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the latest gbif version string — gbif_version","text":"latest available gbif version, string","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_version.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the latest gbif version string — gbif_version","text":"default version can set using option gbif_default_version","code":""},{"path":"https://docs.ropensci.org/gbifdb/reference/gbif_version.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the latest gbif version string — gbif_version","text":"","code":"## Latest local version available: gbif_version(local=TRUE) #> [1] \"-Inf\" ## default version options(gbif_default_version=\"2021-01-01\") gbif_version() #> [1] \"2021-01-01\" if (FALSE) { # interactive() ## Latest online version available: gbif_version() ## All online versions: gbif_version(all=TRUE) }"},{"path":"https://docs.ropensci.org/gbifdb/reference/gbifdb-package.html","id":null,"dir":"Reference","previous_headings":"","what":"gbifdb: High Performance Interface to 'GBIF' — gbifdb-package","title":"gbifdb: High Performance Interface to 'GBIF' — gbifdb-package","text":"high performance interface Global Biodiversity Information Facility, 'GBIF'. contrast 'rgbif', can access small subsets 'GBIF' data web-based queries central server, 'gbifdb' provides enhanced performance R users performing large-scale analyses servers cloud computing providers, providing full support arbitrary 'SQL' 'dplyr' operations complete 'GBIF' data tables (now 1 billion records, terabyte size). 'gbifdb' accesses copy 'GBIF' data 'parquet' format, already readily available commercial computing clouds Amazon Open Data portal Microsoft Planetary Computer, can accessed directly without downloading, downloaded server suitable bandwidth storage space. high-performance techniques local remote access described https://duckdb.org/why_duckdb https://arrow.apache.org/docs/r/articles/fs.html respectively.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/gbifdb/reference/gbifdb-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"gbifdb: High Performance Interface to 'GBIF' — gbifdb-package","text":"Maintainer: Carl Boettiger cboettig@gmail.com (ORCID)","code":""},{"path":"https://docs.ropensci.org/gbifdb/news/index.html","id":"gbifdb-100","dir":"Changelog","previous_headings":"","what":"gbifdb 1.0.0","title":"gbifdb 1.0.0","text":"CRAN release: 2023-10-19 gbif_download() now uses minioclient backend, offering dramatically (100x+) better performance, especially multi-core machines high bandwidth network connections. gbif_local() now defaults duckdb backend, utilizes duckdbfs streamline interface. latest performance duckdb substantially better alternatives. Breaking changes gbif_conn() deprecated","code":""},{"path":"https://docs.ropensci.org/gbifdb/news/index.html","id":"gbifdb-012","dir":"Changelog","previous_headings":"","what":"gbifdb 0.1.2","title":"gbifdb 0.1.2","text":"CRAN release: 2022-05-21 include links DESCRIPTION unpublished methods implemented arrow duckdb high-performance access. update documentation include return value exported functions.","code":""},{"path":"https://docs.ropensci.org/gbifdb/news/index.html","id":"gbifdb-011","dir":"Changelog","previous_headings":"","what":"gbifdb 0.1.1","title":"gbifdb 0.1.1","text":"Automatically detect latest release (see gbif_version()). Works local remote sources, can also report available versions. add gbif_local() return remote table instead connection; paralleling use gbif_remote() gbif_conn() (thus gbif_local() ) gain ability use arrow backend duckdb, now default. improves performance avoids crashes columns requested. default bucket set “us-east-1” (across gbif_download() gbif_remote()) gbif_download() now automatically detects versions, downloads parquet files path parallels remote path (using release-specific subdirectories), allows bucket configured. set to_duckdb=TRUE default gbif_remote(), creating consistent lazy-table interface support windowed functions gbif_conn() (gbif_local()) now automatically detect path recent GBIF version gbif_dir(). need manually set path occurrence.parquet/ subfolder. documentation improved.","code":""}]
